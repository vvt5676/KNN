{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    " 1. Preprocess Dataset\n",
    " 2. Write funcion which will create all combinations of given itemsets.\n",
    " 3. For each combination generate $2^n - 2$ association rules\n",
    " 4. Compute confidence and support for it & based on threshold include it in ruleset.\n",
    " 5. Save all the rules to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 38, 39, 41, 48] \n",
      "No of sample in dataset:  88162\n"
     ]
    }
   ],
   "source": [
    "def preprocess(file_path):\n",
    "    data = []\n",
    "    tmp_data = []\n",
    "    with open(file_path, 'r') as file_input:\n",
    "        for line in file_input:\n",
    "#             line = line.strip('\\n')\n",
    "            tmp_line = []\n",
    "            line = line.split(' ')\n",
    "            for i in range(len(line)-1):\n",
    "                no = int(line[i])\n",
    "                tmp_line.append(no)\n",
    "                tmp_data.append(no)\n",
    "            data.append(tmp_line)\n",
    "    tmp_cntr = Counter(tmp_data)\n",
    "    elements = []\n",
    "    counter = 0\n",
    "    for item in tmp_cntr:\n",
    "        if tmp_cntr[item]>5000:\n",
    "            elements.append(item)\n",
    "    return data, elements, len(tmp_cntr)\n",
    "data, elements, disticnt_values = preprocess(\"retail.dat\")\n",
    "print(elements, \"\\nNo of sample in dataset: \", len(data))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_support(data, set_1, set_2):\n",
    "    count_set1 = 0\n",
    "    count_set2 = 0\n",
    "    count_tot = 0\n",
    "    for row in data:\n",
    "        tmp_cnt1 = 0\n",
    "        tmp_cnt2 = 0\n",
    "        flg = 0\n",
    "        for i in set_1:\n",
    "            if i in row:\n",
    "                tmp_cnt1+=1;\n",
    "        if(tmp_cnt1 == len(set_1)):\n",
    "            count_set1+=1\n",
    "            flg +=1\n",
    "        for i in set_2:\n",
    "            if i in row:\n",
    "                tmp_cnt2+=1\n",
    "        if(tmp_cnt1 == len(set_2)):\n",
    "            count_set2+=1\n",
    "            flg+=1\n",
    "        if flg ==2:\n",
    "            count_tot += 1\n",
    "    tmp_str = \"     \"\n",
    "#     print(tmp_str, count_set1, count_set2, count_tot)\n",
    "    support = count_tot/len(data)\n",
    "    conf = count_tot/count_set1\n",
    "    return support, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules(data, elements, thr_support, thr_confidence):\n",
    "    numbers = len(elements)\n",
    "    length = pow(2, numbers)\n",
    "    rules = []\n",
    "    for i in range(length):\n",
    "        if (i == 0 or i == length-1):\n",
    "            continue\n",
    "        set_1 = []\n",
    "        set_2 = []\n",
    "        binary = bin(i)[2:]\n",
    "        binary = binary.zfill(len(elements))\n",
    "        for i in range(len(elements)):\n",
    "            if(binary[i] == '0'):\n",
    "                set_1.append(elements[i])\n",
    "            else:\n",
    "                set_2.append(elements[i])\n",
    "        support, confidence = get_support(data, set_1, set_2)\n",
    "#         print('  ', set_1)\n",
    "#         print('  ',set_2)\n",
    "#         print('  ',support, confidence)\n",
    "        if thr_confidence < confidence and thr_support < support:\n",
    "            tmp_set = []\n",
    "            tmp_set.append(set_1)\n",
    "            tmp_set.append(set_2)\n",
    "            tmp_set.append(support)\n",
    "            tmp_set.append(confidence)\n",
    "            rules.append(tmp_set)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(data, elements, threshold_support, threshold_confidence):\n",
    "    no_elements = len(elements)\n",
    "    no_of_samples = len(data)\n",
    "    print('we are processing on the ', no_of_samples,' samples')\n",
    "    print('out of that', no_elements, 'are frequently occuring')\n",
    "    rules = []\n",
    "    for i in range(1, pow(2, no_elements)):\n",
    "        binary = bin(i)[2:]\n",
    "        binary = binary.zfill(no_elements)\n",
    "        ele_list = []\n",
    "        for j in range(no_elements):\n",
    "            if binary[j] == '1':\n",
    "                ele_list.append(elements[j])\n",
    "        print(ele_list)\n",
    "        rules_tmp = generate_rules(data, ele_list, threshold_support, threshold_confidence)\n",
    "        \n",
    "        for rule in rules_tmp:\n",
    "            rules.append(rule)\n",
    "    return rules\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88162 [32, 38, 39, 41, 48] 16470\n",
      "we are processing on the  88162  samples\n",
      "out of that 5 are frequently occuring\n",
      "[48]\n",
      "[41]\n",
      "[41, 48]\n",
      "[39]\n",
      "[39, 48]\n",
      "[39, 41]\n",
      "[39, 41, 48]\n",
      "[38]\n",
      "[38, 48]\n",
      "[38, 41]\n",
      "[38, 41, 48]\n",
      "[38, 39]\n",
      "[38, 39, 48]\n",
      "[38, 39, 41]\n",
      "[38, 39, 41, 48]\n",
      "[32]\n",
      "[32, 48]\n",
      "[32, 41]\n",
      "[32, 41, 48]\n",
      "[32, 39]\n",
      "[32, 39, 48]\n",
      "[32, 39, 41]\n",
      "[32, 39, 41, 48]\n",
      "[32, 38]\n",
      "[32, 38, 48]\n",
      "[32, 38, 41]\n",
      "[32, 38, 41, 48]\n",
      "[32, 38, 39]\n",
      "[32, 38, 39, 48]\n",
      "[32, 38, 39, 41]\n",
      "[32, 38, 39, 41, 48]\n",
      "vaibhav\n",
      "[[41], [48], 0.16951747918604387, 1.0]\n",
      "[[48], [41], 0.47792699802636057, 1.0]\n",
      "[[39], [48], 0.5747941289898142, 1.0]\n",
      "[[48], [39], 0.47792699802636057, 1.0]\n",
      "[[39], [41], 0.5747941289898142, 1.0]\n",
      "[[41], [39], 0.16951747918604387, 1.0]\n",
      "[[38], [48], 0.17690161293981535, 1.0]\n",
      "[[48], [38], 0.47792699802636057, 1.0]\n",
      "[[38], [41], 0.17690161293981535, 1.0]\n",
      "[[41], [38], 0.16951747918604387, 1.0]\n",
      "[[38], [39], 0.17690161293981535, 1.0]\n",
      "[[39], [38], 0.5747941289898142, 1.0]\n",
      "[[38, 39], [41, 48], 0.1173408044282117, 1.0]\n",
      "[[38, 48], [39, 41], 0.09010684875569973, 1.0]\n",
      "[[39, 41], [38, 48], 0.12946620993171662, 1.0]\n",
      "[[39, 48], [38, 41], 0.33055057734624893, 1.0]\n",
      "[[41, 48], [38, 39], 0.10228896803611533, 1.0]\n",
      "[[32], [48], 0.1720355708808784, 1.0]\n",
      "[[48], [32], 0.47792699802636057, 1.0]\n",
      "[[32], [41], 0.1720355708808784, 1.0]\n",
      "[[41], [32], 0.16951747918604387, 1.0]\n",
      "[[32], [39], 0.1720355708808784, 1.0]\n",
      "[[39], [32], 0.5747941289898142, 1.0]\n",
      "[[32, 39], [41, 48], 0.09590299675597196, 1.0]\n",
      "[[32, 48], [39, 41], 0.0911276967400921, 1.0]\n",
      "[[39, 41], [32, 48], 0.12946620993171662, 1.0]\n",
      "[[39, 48], [32, 41], 0.33055057734624893, 1.0]\n",
      "[[41, 48], [32, 39], 0.10228896803611533, 1.0]\n",
      "[[32], [38], 0.1720355708808784, 1.0]\n",
      "[[38], [32], 0.17690161293981535, 1.0]\n",
      "[[32, 48], [38, 41], 0.0911276967400921, 1.0]\n",
      "[[38, 48], [32, 41], 0.09010684875569973, 1.0]\n",
      "[[41, 48], [32, 38], 0.10228896803611533, 1.0]\n",
      "[[32, 39], [38, 48], 0.09590299675597196, 1.0]\n",
      "[[32, 48], [38, 39], 0.0911276967400921, 1.0]\n",
      "[[38, 39], [32, 48], 0.1173408044282117, 1.0]\n",
      "[[38, 48], [32, 39], 0.09010684875569973, 1.0]\n",
      "[[39, 48], [32, 38], 0.33055057734624893, 1.0]\n",
      "[[32, 39], [38, 41], 0.09590299675597196, 1.0]\n",
      "[[38, 39], [32, 41], 0.1173408044282117, 1.0]\n",
      "[[39, 41], [32, 38], 0.12946620993171662, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file_name = \"retail.dat\"\n",
    "    data, elements, distinct_values = preprocess(file_name)\n",
    "    print(len(data), elements, distinct_values)\n",
    "    rules = generate_combinations(data, elements, 0.05, 0.7)\n",
    "    print('vaibhav')\n",
    "    for rule in rules:\n",
    "        print(rule)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
